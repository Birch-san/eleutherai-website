---
title: "News & Announcements"
date: 2021-02-26T20:18:54+03:00
layout: page
---

## News & Announcements


## {class="content-block"}
- {{<date year="2021" month="04" day="20">}}
- **Blog**  
Rotary Positional Embedding (RoPE) is a new type of position encoding that unifies absolute and relative approaches.  
[Rotary Embeddings: A Relative Revolution >](https://blog.eleuther.ai/rotary-embeddings/)

## {class="content-block"}
- {{<date year="2021" month="03" day="31">}}
- **GPT&#8288;-&#8288;Neo**  
GPT&#8288;-&#8288;Neo 1.3B and 2.7B are now available on Hugging Face Model Hub! Run the models with Transformers or call for them through their on-demand Inference API.  
[EleutherAI on Model Hub >](https://huggingface.co/EleutherAI)

## {class="content-block"}
- {{<date year="2021" month="03" day="21">}}
- **GPT&#8288;-&#8288;Neo**  
GPT&#8288;-&#8288;Neo 1.3B and 2.7B, trained on the Pile, are now available to run with the GPT&#8288;-&#8288;Neo framework.  
[GPT-Neo on Github >](https://github.com/EleutherAI/gpt-neo/)

## {class="content-block"}
- {{<date year="2021" month="01" day="01">}}
- **The Pile**  
We are proud to announce the release of the Pile, a free and publicly available 800GB dataset of diverse English text for language modeling!  
[Visit the Pile >](https://pile.eleuther.ai/)